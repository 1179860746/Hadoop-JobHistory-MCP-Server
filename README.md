# JobHistory MCP Server

åŸºäº Hadoop JobHistory Server REST API çš„ MCP (Model Context Protocol) æœåŠ¡å™¨å®ç°ã€‚

è¯¥æœåŠ¡å…è®¸ AI åŠ©æ‰‹ï¼ˆå¦‚ Claudeã€Cursorï¼‰é€šè¿‡ MCP åè®®æŸ¥è¯¢ Hadoop MapReduce ä½œä¸šçš„å†å²ä¿¡æ¯ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ” **ä½œä¸šæŸ¥è¯¢**: åˆ—å‡ºå’Œæœç´¢ MapReduce ä½œä¸šï¼Œæ”¯æŒå¤šç§è¿‡æ»¤æ¡ä»¶
- ğŸ“Š **è¯¦ç»†ä¿¡æ¯**: è·å–ä½œä¸šã€ä»»åŠ¡ã€å°è¯•çš„å®Œæ•´è¯¦æƒ…
- ğŸ“ˆ **è®¡æ•°å™¨æŸ¥è¯¢**: æŸ¥çœ‹ä½œä¸šå’Œä»»åŠ¡çš„æ‰§è¡Œç»Ÿè®¡æ•°æ®
- âš™ï¸ **é…ç½®æŸ¥è¯¢**: è·å–ä½œä¸šè¿è¡Œæ—¶çš„é…ç½®å‚æ•°
- ğŸ”„ **çµæ´»è¾“å‡º**: æ”¯æŒ Markdownï¼ˆäººç±»å¯è¯»ï¼‰å’Œ JSONï¼ˆç¨‹åºå¤„ç†ï¼‰ä¸¤ç§æ ¼å¼

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd JobHistoryMcpServer
pip install -r requirements.txt
```

### 2. é…ç½® JobHistory Server åœ°å€

é€šè¿‡ç¯å¢ƒå˜é‡é…ç½® JobHistory Server çš„åœ°å€ï¼š

```bash
export JOBHISTORY_URL="http://your-history-server:19888/ws/v1/history"
```

é»˜è®¤åœ°å€ä¸º `http://localhost:19888/ws/v1/history`

### 3. è¿è¡ŒæœåŠ¡

```bash
python jobhistory_mcp.py
```

## MCP å®¢æˆ·ç«¯é…ç½®

### Cursor é…ç½®

åœ¨ `~/.cursor/mcp.json` ä¸­æ·»åŠ ï¼š

```json
{
  "mcpServers": {
    "jobhistory_mcp": {
      "command": "python",
      "args": ["/path/to/JobHistoryMcpServer/jobhistory_mcp.py"],
      "env": {
        "JOBHISTORY_URL": "http://your-history-server:19888/ws/v1/history"
      }
    }
  }
}
```

### Claude Desktop é…ç½®

åœ¨ `~/Library/Application Support/Claude/claude_desktop_config.json` ä¸­æ·»åŠ ï¼š

```json
{
  "mcpServers": {
    "jobhistory_mcp": {
      "command": "python",
      "args": ["/path/to/JobHistoryMcpServer/jobhistory_mcp.py"],
      "env": {
        "JOBHISTORY_URL": "http://your-history-server:19888/ws/v1/history"
      }
    }
  }
}
```

## å¯ç”¨å·¥å…·åˆ—è¡¨

| å·¥å…·å | åŠŸèƒ½æè¿° |
|--------|----------|
| `jobhistory_get_info` | è·å– JobHistory Server åŸºæœ¬ä¿¡æ¯ |
| `jobhistory_list_jobs` | åˆ—å‡ºä½œä¸šï¼ˆæ”¯æŒè¿‡æ»¤å’Œåˆ†é¡µï¼‰ |
| `jobhistory_get_job` | è·å–ä½œä¸šè¯¦æƒ… |
| `jobhistory_get_job_counters` | è·å–ä½œä¸šè®¡æ•°å™¨ |
| `jobhistory_get_job_conf` | è·å–ä½œä¸šé…ç½® |
| `jobhistory_get_job_attempts` | è·å–ä½œä¸š AM å°è¯•åˆ—è¡¨ |
| `jobhistory_list_tasks` | åˆ—å‡ºä½œä¸šçš„ä»»åŠ¡ |
| `jobhistory_get_task` | è·å–ä»»åŠ¡è¯¦æƒ… |
| `jobhistory_get_task_counters` | è·å–ä»»åŠ¡è®¡æ•°å™¨ |
| `jobhistory_list_task_attempts` | åˆ—å‡ºä»»åŠ¡å°è¯• |
| `jobhistory_get_task_attempt` | è·å–ä»»åŠ¡å°è¯•è¯¦æƒ… |
| `jobhistory_get_task_attempt_counters` | è·å–ä»»åŠ¡å°è¯•è®¡æ•°å™¨ |

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: æŸ¥è¯¢æœ€è¿‘çš„ä½œä¸š

```
è¯·åˆ—å‡ºæœ€è¿‘ 10 ä¸ª MapReduce ä½œä¸š
```

AI åŠ©æ‰‹ä¼šè°ƒç”¨ `jobhistory_list_jobs` å·¥å…·ï¼Œå‚æ•° `limit=10`ã€‚

### ç¤ºä¾‹ 2: æŸ¥è¯¢å¤±è´¥çš„ä½œä¸š

```
æŸ¥æ‰¾æ‰€æœ‰å¤±è´¥çš„ MapReduce ä½œä¸š
```

AI åŠ©æ‰‹ä¼šè°ƒç”¨ `jobhistory_list_jobs` å·¥å…·ï¼Œå‚æ•° `state="FAILED"`ã€‚

### ç¤ºä¾‹ 3: è·å–ä½œä¸šè¯¦æƒ…

```
è·å–ä½œä¸š job_1326381300833_2_2 çš„è¯¦ç»†ä¿¡æ¯
```

AI åŠ©æ‰‹ä¼šè°ƒç”¨ `jobhistory_get_job` å·¥å…·ã€‚

### ç¤ºä¾‹ 4: åˆ†æä½œä¸šæ€§èƒ½

```
åˆ†æä½œä¸š job_xxx çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬ä»»åŠ¡æ‰§è¡Œæ—¶é—´å’Œè®¡æ•°å™¨
```

AI åŠ©æ‰‹ä¼šä¾æ¬¡è°ƒç”¨å¤šä¸ªå·¥å…·è·å–å…¨é¢ä¿¡æ¯ã€‚

## é¡¹ç›®ç»“æ„

```
JobHistoryMcpServer/
â”œâ”€â”€ README.md                    # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ requirements.txt             # Python ä¾èµ–
â”œâ”€â”€ jobhistory_mcp.py           # MCP Server ä¸»ä»£ç 
â”œâ”€â”€ Dockerfile                   # Docker é•œåƒæ„å»ºæ–‡ä»¶
â”œâ”€â”€ docker-compose.yml          # Docker Compose é…ç½®
â”œâ”€â”€ .dockerignore               # Docker å¿½ç•¥æ–‡ä»¶
â””â”€â”€ docs/
    â”œâ”€â”€ REST_API.md             # JobHistory REST API æ–‡æ¡£
    â”œâ”€â”€ MCP_USAGE.md            # MCP ä½¿ç”¨è¯´æ˜
    â”œâ”€â”€ CODE_EXPLANATION.md     # ä»£ç è¯¦è§£
    â””â”€â”€ DOCKER.md               # Docker éƒ¨ç½²æŒ‡å—
```

## Docker éƒ¨ç½²

### æ„å»ºé•œåƒ

```bash
cd JobHistoryMcpServer
docker build -t jobhistory-mcp-server:latest .
```

### è¿è¡Œå®¹å™¨

```bash
docker run -i --rm \
  -e JOBHISTORY_URL="http://your-hadoop-cluster:19888/ws/v1/history" \
  jobhistory-mcp-server:latest
```

### Cursor MCP é…ç½®ï¼ˆDocker æ–¹å¼ï¼‰

```json
{
  "mcpServers": {
    "jobhistory_mcp": {
      "command": "docker",
      "args": [
        "run", "-i", "--rm",
        "-e", "JOBHISTORY_URL=http://your-hadoop-cluster:19888/ws/v1/history",
        "jobhistory-mcp-server:latest"
      ]
    }
  }
}
```

è¯¦ç»†è¯´æ˜è¯·å‚è€ƒ [Docker éƒ¨ç½²æŒ‡å—](docs/DOCKER.md)

## æ—¥å¿—é…ç½®

æ—¥å¿—ç³»ç»Ÿè®°å½•å·¥å…·è°ƒç”¨å’Œ REST è¯·æ±‚ï¼Œæ”¯æŒæ»šåŠ¨æ—¥å¿—ã€‚

### ç¯å¢ƒå˜é‡

| å˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `LOG_LEVEL` | `INFO` | æ—¥å¿—çº§åˆ« (DEBUG/INFO/WARNING/ERROR) |
| `LOG_FILE` | `./logs/jobhistory_mcp.log` | æ—¥å¿—æ–‡ä»¶è·¯å¾„ |
| `LOG_MAX_SIZE` | `268435456` (256MB) | å•æ–‡ä»¶æœ€å¤§å¤§å° |
| `LOG_BACKUP_COUNT` | `5` | ä¿ç•™æ–‡ä»¶æ•°é‡ |
| `LOG_TO_STDERR` | `true` | æ˜¯å¦è¾“å‡ºåˆ° stderr |

### æ—¥å¿—ç¤ºä¾‹

```
2024-01-15 10:30:45 | INFO  | a1b2c3d4 | [TOOL_CALL] jobhistory_list_jobs, params: {"limit": 10}
2024-01-15 10:30:45 | INFO  | a1b2c3d4 | [REST_REQ] GET http://hadoop:19888/ws/v1/history/mapreduce/jobs?limit=10
2024-01-15 10:30:46 | INFO  | a1b2c3d4 | [REST_RSP] 200 OK, size: 1523 bytes, duration: 856.23ms
2024-01-15 10:30:46 | INFO  | a1b2c3d4 | [TOOL_RSP] success, size: 1856 bytes, duration: 892.45ms
```

è¯¦ç»†è¯´æ˜è¯·å‚è€ƒ [æ—¥å¿—é…ç½®æŒ‡å—](docs/LOGGING.md)

## æ–‡æ¡£

- [REST API æ–‡æ¡£](docs/REST_API.md) - JobHistory Server REST API å®Œæ•´è¯´æ˜
- [MCP ä½¿ç”¨è¯´æ˜](docs/MCP_USAGE.md) - MCP Server é…ç½®å’Œä½¿ç”¨æŒ‡å—
- [ä»£ç è¯¦è§£](docs/CODE_EXPLANATION.md) - ä»£ç ç»“æ„å’Œå®ç°è¯´æ˜
- [Docker éƒ¨ç½²æŒ‡å—](docs/DOCKER.md) - Docker æ„å»ºå’Œéƒ¨ç½²è¯´æ˜
- [æ—¥å¿—é…ç½®æŒ‡å—](docs/LOGGING.md) - æ—¥å¿—åŠŸèƒ½å’Œé…ç½®è¯´æ˜

## ä¾èµ–

- Python 3.9+
- mcp >= 1.0.0 (FastMCP)
- pydantic >= 2.0.0
- httpx >= 0.25.0

## è®¸å¯è¯

MIT License
